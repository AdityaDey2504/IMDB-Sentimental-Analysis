{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58df164b-e812-42ba-a8c7-8005e2e43658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b614d7ae-cc82-4fc9-b121-f11280838f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_dictionary=json.load(open(\"kaggle.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "259adc16-69c1-43aa-aec1-3e8e74d56e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KAGGLE_USERNAME\"]= kaggle_dictionary[\"username\"]\n",
    "os.environ[\"KAGGLE_KEY\"]= kaggle_dictionary[\"key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a176ccba-29fd-4ffc-9d79-ff85eee24e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
      "License(s): other\n",
      "Downloading imdb-dataset-of-50k-movie-reviews.zip to C:\\Users\\theon\\Jupyter Projects\\IMDB Sentimental Analysis\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/25.7M [00:00<?, ?B/s]\n",
      "  4%|3         | 1.00M/25.7M [00:01<00:40, 646kB/s]\n",
      "  8%|7         | 2.00M/25.7M [00:01<00:19, 1.30MB/s]\n",
      " 12%|#1        | 3.00M/25.7M [00:01<00:11, 2.08MB/s]\n",
      " 19%|#9        | 5.00M/25.7M [00:02<00:05, 3.93MB/s]\n",
      " 27%|##7       | 7.00M/25.7M [00:02<00:03, 5.98MB/s]\n",
      " 35%|###5      | 9.00M/25.7M [00:02<00:02, 7.96MB/s]\n",
      " 43%|####2     | 11.0M/25.7M [00:02<00:01, 10.1MB/s]\n",
      " 51%|#####     | 13.0M/25.7M [00:02<00:01, 11.2MB/s]\n",
      " 58%|#####8    | 15.0M/25.7M [00:02<00:00, 12.8MB/s]\n",
      " 66%|######6   | 17.0M/25.7M [00:02<00:00, 14.0MB/s]\n",
      " 74%|#######3  | 19.0M/25.7M [00:03<00:00, 14.9MB/s]\n",
      " 82%|########1 | 21.0M/25.7M [00:03<00:00, 14.9MB/s]\n",
      " 89%|########9 | 23.0M/25.7M [00:03<00:00, 15.5MB/s]\n",
      " 97%|#########7| 25.0M/25.7M [00:03<00:00, 16.3MB/s]\n",
      "100%|##########| 25.7M/25.7M [00:03<00:00, 7.82MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29081f66-7d9c-4bcb-8468-e63edbd4731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(\"imdb-dataset-of-50k-movie-reviews.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "765afe50-16c8-49e2-a222-d796f232d7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da453372-d462-49f0-845a-bbc3d148716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "data.replace({\"sentiment\":{\"positive\":1,\"negative\":0}},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c61bc1c1-ca5a-4caa-a26d-a3753f242fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data=train_test_split(data,test_size=0.25,random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1189de6-1eef-43bb-a5e2-17547d89cb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\theon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\theon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\theon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\theon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42992a00-320a-4cbc-82cb-73830b74c179",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3099d22-c4b9-49f7-9a1d-2ff37d6903e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_l=train_data\n",
    "test_data_l=test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d42726e4-8913-431c-bebe-c16675024335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_review(review):\n",
    "    words=word_tokenize(review)\n",
    "    lemmatized_review=' '.join(lemmatizer.lemmatize(word, pos='v') for word in words)\n",
    "    return lemmatized_review\n",
    "\n",
    "train_data_l['lemmatized_review'] = train_data['review'].apply(lemmatize_review)\n",
    "test_data_l['lemmatized_review'] = test_data['review'].apply(lemmatize_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5e9c919-40d2-4bb2-b6a6-c6afe4e0897c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\theon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words=set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
    "\n",
    "train_data_l['lemmatized_review'] = train_data_l['lemmatized_review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcfb4565-dd77-4bbb-a38f-aff08438726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(train_data_l['lemmatized_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d41b73b-89e2-4b74-a1ed-51a2af01a804",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(tokenizer.texts_to_sequences(train_data['lemmatized_review']), maxlen=200)\n",
    "x_test = pad_sequences(tokenizer.texts_to_sequences(test_data['lemmatized_review']), maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff65805b-24ee-4940-8b8c-2bbc44ab3b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train_data[\"sentiment\"]\n",
    "y_test=test_data[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3dd3749-a696-42c4-9a0a-925a40c3be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train.astype(int))\n",
    "y_test = np.array(y_test.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66b9dacd-86b1-41b5-be67-81b214e0bb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(input_dim=5000,output_dim=128))\n",
    "model.add(LSTM(128,dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "793c72fc-80c6-4c3a-82ec-b96746a768a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 128)         640000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               131584    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 771,713\n",
      "Trainable params: 771,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build(input_shape=(None, 200))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "738c2d1e-6436-4dd2-8610-6efc2060931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3293b8c-d825-4ac1-8194-af88432dc816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "203/469 [===========>..................] - ETA: 1:25 - loss: 0.4332 - accuracy: 0.7961"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,epochs=10,batch_size=64,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18daf5eb-e22e-4e71-a77c-b7da350fc549",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss,accuracy=model.evaluate(x_test,y_test)\n",
    "print(f\"Test Loss: {loss}\\nTest Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a68a2b-3c96-4de8-b1b2-1ccb5870bbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb77f34-3788-4940-bca6-66fe1c2bf3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "report = classification_report(y_test, y_pred, target_names=['negative', 'positive'])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22db4a85-4327-4c8b-b396-43d36fbe5c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_review(review):\n",
    "    words = review.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return lemmatized_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0ca8c0-b708-4c4e-b16d-c95fe98a50aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(review):\n",
    "    lemmantized_review=lemmatize_review(review)\n",
    "    sequence = tokenizer.texts_to_sequences([' '.join(lemmantized_review)])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=200)\n",
    "    predictions = model.predict(padded_sequence)\n",
    "    sentiment = \"positive\" if predictions[0][0] > 0.5 else \"negative\"\n",
    "    print(predictions[0][0])\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6603ea6b-cdf5-48d6-a32d-2a7c5f8608d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
